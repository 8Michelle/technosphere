{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, SparsePCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "from lightgbm import LGBMClassifier\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, vect_type='count', **voc_params):\n",
    "    if vect_type == 'count':\n",
    "        vectorizer = CountVectorizer(**voc_params)\n",
    "    elif vect_type == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer(min_df=2)\n",
    "    data_vect = vectorizer.fit_transform(data.fillna('')).todense()\n",
    "    scaler = StandardScaler()\n",
    "    data_vect = scaler.fit_transform(data_vect)\n",
    "    return data_vect\n",
    "\n",
    "def make_pca(data_vect):\n",
    "    pca = PCA()\n",
    "    pca.fit(data_vect)\n",
    "    n_c = (pca.explained_variance_ratio_.cumsum() < 0.95).sum()\n",
    "    pca = PCA(n_components=n_c)\n",
    "    data_vect = pca.fit_transform(data_vect)\n",
    "    return data_vect\n",
    "\n",
    "def get_devs(df, n_vecs):\n",
    "    df_list = []\n",
    "    for i in tqdm(df['group_id'].unique(), total=129):\n",
    "        df_i = df[df['group_id'] == i]\n",
    "        vect_i = np.array(df_i.loc[:, [f'{j}_f' for j in range(n_vecs)]])\n",
    "        mean_i = np.mean(vect_i, axis=0)\n",
    "        df_i['dev'] = np.apply_along_axis(lambda x: cosine(x, mean_i), axis=1, arr=vect_i)\n",
    "        df_list.append(df_i)\n",
    "    df_with_dev = pd.concat(df_list)\n",
    "    df = df_with_dev.drop([f'{i}_f' for i in range(n_vecs)], 1)\n",
    "    return df\n",
    "\n",
    "def show_hist(df, column='dev'):\n",
    "    plt.hist(df[df['target'] == 0][column].fillna(0), bins=100, normed=True, label='Out of group')\n",
    "    plt.hist(df[df['target'] == 1][column].fillna(0), bins=100, normed=True, alpha=0.7, label='In group')\n",
    "    plt.title('dev distribution')\n",
    "    plt.legend()\n",
    "\n",
    "def get_th(proba, y_test):\n",
    "    scores = []\n",
    "    ths = np.arange(0.1, 0.9, 0.1)\n",
    "    for i in ths:\n",
    "        scores.append(f1_score(y_test, (proba > i)[:, 1]))\n",
    "    ind = scores.index(max(scores))\n",
    "    th = np.arange(0.1, 0.9, 0.1)[ind]\n",
    "    score = f1_score((proba > th)[:, 1], y_test)\n",
    "    return score, th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train dists preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('data/clean_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_params = {'min_df': 5, 'max_df': 0.8}\n",
    "vect_titles = get_vectors(titles['clean_title'], **voc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.join(pd.DataFrame(vect_titles, columns=[f'{i}_f' for i in range(vect_titles.shape[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_titles = pd.merge(df_train, titles, how='left', on='doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ddbf3f7e404b6c8fb7a8c3e4dc74b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for group_id in tqdm(range(1, 129), total=128):\n",
    "    sample = df_train_titles[df_train_titles['group_id'] == group_id]\n",
    "    summary = np.array(sample.loc[:, [f'{i}_f' for i in range(4222)]])\n",
    "    pairwise = pd.DataFrame(\n",
    "        squareform(pdist(summary, metric='cosine')),\n",
    "        columns = sample['pair_id'],\n",
    "        index = sample['pair_id']\n",
    "    )\n",
    "    pairwise = pairwise.replace(0, np.nan)\n",
    "    pairwise = pairwise.describe().T\n",
    "    pairwise = pairwise.reset_index()\n",
    "    data.append(pairwise)\n",
    "df_train_data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist = pd.merge(df_train, df_train_data, how='left', on='pair_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist.to_csv('data/dist_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dists preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_titles = pd.merge(df_test, titles, how='left', on='doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee657166754d4343a4a5a435b833c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "groups = df_test_titles['group_id'].unique()\n",
    "for group_id in tqdm(groups, total=groups.shape[0]):\n",
    "    sample = df_test_titles[df_test_titles['group_id'] == group_id]\n",
    "    summary = np.array(sample.loc[:, [f'{i}_f' for i in range(4222)]])\n",
    "    pairwise = pd.DataFrame(\n",
    "        squareform(pdist(summary, metric='cosine')),\n",
    "        columns = sample['pair_id'],\n",
    "        index = sample['pair_id']\n",
    "    )\n",
    "    pairwise = pairwise.replace(0, np.nan)\n",
    "    pairwise = pairwise.describe().T\n",
    "    pairwise = pairwise.reset_index()\n",
    "    data.append(pairwise)\n",
    "df_test_data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist = pd.merge(df_test, df_test_data, how='left', on='pair_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train devs preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61521c6307d4f988bfcdc330f281d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_devs = get_devs(df_train_titles, titles.shape[1] - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_devs = df_train_devs.drop(['group_id', 'doc_id', 'target', 'clean_title'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist_devs = pd.merge(df_train_devs, df_train_dist, how='inner', on='pair_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist_devs.to_csv('data/dist_devs_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test devs preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e989e611442476e88c79ffb2ddad0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_devs = get_devs(df_test_titles, titles.shape[1] - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_devs = df_test_devs.drop(['group_id', 'doc_id', 'clean_title'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist_devs = pd.merge(df_test_devs, df_test_dist, how='inner', on='pair_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dist_devs.to_csv('data/dist_devs_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding train word intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_int = pd.read_csv('/Users/michelle/Downloads/fich_20_coins_1_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_int = df_train_int.drop(['Unnamed: 0', 'target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = df_train_dist_devs.join(df_train_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding test word intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_int = pd.read_csv('/Users/michelle/Downloads/fich_20_coins_1_avg_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_int = df_test_int.drop(['Unnamed: 0'], 1)\n",
    "df_test_all = df_test_dist_devs.join(df_test_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = df_train_all.drop(['pair_id', 'group_id', 'doc_id', 'target', 'count'], 1)\n",
    "df_train_metadata = df_train_all.loc[:, ['pair_id', 'group_id', 'doc_id', 'target']]\n",
    "df_test_data = df_test_all.drop(['pair_id', 'group_id', 'doc_id', 'count'], 1)\n",
    "df_test_metadata = df_test_all.loc[:, ['pair_id', 'group_id', 'doc_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_cross_val_score(model, df, train_subset=['dev'], cv=5):\n",
    "    indices = df['group_id'].unique()\n",
    "    result = []\n",
    "    ths = 0\n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "    \n",
    "    for train_ids, test_ids in kf.split(indices):\n",
    "        train_data = df[df['group_id'].isin(train_ids)]\n",
    "        test_data = df[df['group_id'].isin(test_ids)]\n",
    "        model.fit(train_data.loc[:, train_subset].fillna(0), train_data['target'])\n",
    "        proba = model.predict_proba(test_data.loc[:, train_subset].fillna(0))\n",
    "        score, th = get_th(proba, test_data['target'])\n",
    "        ths += th\n",
    "        result.append(score)\n",
    "    return sum(result) / len(result), ths / len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = list(df_train_all.columns)\n",
    "train_subset.remove('pair_id')\n",
    "train_subset.remove('group_id')\n",
    "train_subset.remove('doc_id')\n",
    "train_subset.remove('target')\n",
    "train_subset.remove('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7503680460283206 0.56\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(class_weight='balanced', n_estimators=100000, max_depth=3, learning_rate=0.0001)\n",
    "score, th = linear_model_cross_val_score(model, df_train_all, train_subset=train_subset, cv=5)\n",
    "print(score, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_bytree=1.0, importance_type='split',\n",
       "               learning_rate=0.0001, max_depth=3, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100000,\n",
       "               n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(class_weight='balanced', n_estimators=100000, max_depth=3, learning_rate=0.0001)\n",
    "model.fit(df_train_all.loc[:, train_subset], df_train_all['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict_proba(df_test_all.loc[:, train_subset])[:, 1]\n",
    "predict = (proba > th)\n",
    "df_test_all['target'] = predict\n",
    "df_test_all['target'] = df_test_all['target'].apply(lambda x: int(x))\n",
    "df_test_all.loc[:, ['pair_id', 'target']].to_csv('predictions/all_30_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_train_data_norm = scaler.fit_transform(df_train_data)\n",
    "df_test_data_norm = scaler.transform(df_test_data)\n",
    "df_train_all_norm = df_train_metadata.join(pd.DataFrame(df_train_data_norm))\n",
    "df_test_all_norm = df_test_metadata.join(pd.DataFrame(df_test_data_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_norm = list(df_train_all_norm.drop(['pair_id', 'group_id', 'doc_id', 'target'], 1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7474013767351569 0.56\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(class_weight='balanced', n_estimators=100000, max_depth=3, learning_rate=0.0001)\n",
    "score, th = linear_model_cross_val_score(model, df_train_all_norm, train_subset=train_subset_norm, cv=5)\n",
    "print(score, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(class_weight='balanced', n_estimators=100000, max_depth=3, learning_rate=0.0001)\n",
    "model.fit(df_train_all_norm.loc[:, train_subset_norm], df_train_all_norm['target'])\n",
    "proba = model.predict_proba(df_test_all_norm.loc[:, train_subset_norm])[:, 1]\n",
    "predict = (proba > th)\n",
    "df_test_all_norm['target'] = predict\n",
    "df_test_all_norm['target'] = df_test_all_norm['target'].apply(lambda x: int(x))\n",
    "df_test_all_norm.loc[:, ['pair_id', 'target']].to_csv('predictions/all_norm_30_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers dist train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = pd.read_csv('data/all_headers.tsv', sep='\\t')\n",
    "voc_params = {'min_df': 5, 'max_df': 0.8}\n",
    "vect_headers = get_vectors(headers['headers'], **voc_params)\n",
    "headers = headers.join(pd.DataFrame(vect_headers, columns=[f'{i}_f' for i in range(vect_headers.shape[1])]))\n",
    "df_train_headers = pd.merge(df_train, headers, how='left', on='doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vect_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train_titles\n",
    "del df_test_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all.to_csv('data/all_test_30_05.csv', index=False)\n",
    "df_train_all.to_csv('data/all_train_30_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
